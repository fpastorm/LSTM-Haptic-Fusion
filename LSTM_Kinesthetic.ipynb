{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Kinesthetic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NeWVBhf1VxlH",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4j2OeaC5pW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install keras_layer_normalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKXgE6TyNCWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import scipy.io\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Input, Conv2DTranspose, LSTM, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, Flatten, Dense, MaxPooling2D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "\n",
        "drive.mount('/content/gdrive',force_remount=True)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAHUc7Xk-I2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add your own path\n",
        "FUSION2020_FOLDER_PATH = \"/content/gdrive/My Drive/FUSION2020\"\n",
        "NUMBER_OF_EXAMPLES_FOR_EACH_CLASS = 60\n",
        "NUMBER_OF_EXAMPLES_FOR_TRAINING_AND_VALIDATION = 15\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPIYoswKSDmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_training_and_validation_example_list(path, number_of_examples):\n",
        "  training_matrix_paths = []\n",
        "  for i in range(1, number_of_examples+1):\n",
        "    training_matrix_paths = training_matrix_paths + glob(os.path.join(path, \"*_{}.mat\".format(i)))\n",
        "  return training_matrix_paths\n",
        "\n",
        "def get_all_matrix_paths(path):\n",
        "  number_of_matrix_paths = len(glob(os.path.join(path, \"*.mat\")))\n",
        "  all_matrix_paths = []\n",
        "  for i in range(1, number_of_matrix_paths+1):\n",
        "    all_matrix_paths = all_matrix_paths + glob(os.path.join(path, \"*_{}.mat\".format(i)))\n",
        "  return all_matrix_paths\n",
        "\n",
        "def read_all_matrix_from_object_folder_obtaining_training_and_evaluation(path, number_of_training_examples):\n",
        "  all_matrix_paths = get_all_matrix_paths(path)\n",
        "  training_matrix_paths = get_training_and_validation_example_list(path,number_of_training_examples)\n",
        "  print(training_matrix_paths)\n",
        "  training_object_data = None\n",
        "  evaluation_object_data = None\n",
        "  training_matrix_index = 0\n",
        "  evaluation_matrix_index = 0\n",
        "\n",
        "  for matrix_path in all_matrix_paths:\n",
        "    matrix = scipy.io.loadmat(matrix_path)\n",
        "    matrix = matrix[\"datos2\"]\n",
        "    print(\"Matrix {} shape\".format(matrix_path))\n",
        "    print(matrix.shape)\n",
        "    if matrix_path in training_matrix_paths:\n",
        "      if training_object_data is None:\n",
        "        training_object_data = -1 * np.ones((len(training_matrix_paths), matrix.shape[0], matrix.shape[1]))\n",
        "      training_object_data[training_matrix_index] = matrix\n",
        "      training_matrix_index += 1   \n",
        "\n",
        "    else:\n",
        "      if evaluation_object_data is None:\n",
        "        evaluation_object_data = -1 * np.ones((NUMBER_OF_EXAMPLES_FOR_EACH_CLASS-len(training_matrix_paths), matrix.shape[0], matrix.shape[1]))\n",
        "      evaluation_object_data[evaluation_matrix_index] = matrix\n",
        "      evaluation_matrix_index += 1\n",
        "\n",
        "  print(training_object_data.shape)\n",
        "  print(evaluation_object_data.shape)\n",
        "  return training_object_data, evaluation_object_data\n",
        "\n",
        "def read_training_and_evaluation_objects_data(path,number_of_training_examples):\n",
        "  nom_labels = [\"antiseptic_bottle_\", \"ball_l_\",\"beard_shampoo_\", \"body_gel_\", \"basket_ball_\",\n",
        "                \"coke_bottle_\",\"constructable_green_brick_\", \"constructable_mixed_brick_\",\n",
        "                \"constructable_red_brick_\", \"constructable_yellow_brick_\", \"energy_drink_can_\", \n",
        "                 \"flux_bottle_\", \"gears_box_\", \"gorillas_ball_\", \"grey_mouse_\", \"mixed_nut_\", \n",
        "                \"mixed_washer_\", \"mouse_\", \"nestea_bottle_\",\"nut_m6_\", \"nut_m8_\", \"nut_m10_\",\n",
        "                \"rivets_box_\", \"roll_wheel_\", \"rubber_pipe_\", \"soda_can_\", \n",
        "                \"sponge_rough_\", \"sponge_rough_inclusions_\", \"sponge_scrunchy_\",\n",
        "                \"sponge_smooth_\", \"sponge_smooth_inclusions_\", \"sponge_tube_\", \n",
        "                \"sunscreen_lotion_\", \"tennis_ball_\", \"water_bottle_\",\"world_ball_\"] \n",
        "  all_objects_folders_path = []\n",
        "  for nom_label in nom_labels:\n",
        "    all_objects_folders_path = all_objects_folders_path + glob(os.path.join(path,nom_label))\n",
        "  all_objects_training_data = None\n",
        "  all_objects_evaluation_data = None\n",
        "  all_objects_training_labels = []\n",
        "  all_objects_evaluation_labels = []\n",
        "\n",
        "  for object_index, object_folder_path in enumerate(all_objects_folders_path):\n",
        "    \n",
        "    training_object_data, evaluation_object_data = read_all_matrix_from_object_folder_obtaining_training_and_evaluation(object_folder_path,number_of_training_examples)\n",
        "\n",
        "    if all_objects_training_data is None:\n",
        "      all_objects_training_data = training_object_data\n",
        "    else:\n",
        "      all_objects_training_data = np.concatenate((all_objects_training_data, training_object_data), axis = 0)\n",
        "\n",
        "    if all_objects_evaluation_data is None:\n",
        "      all_objects_evaluation_data = evaluation_object_data\n",
        "    else:\n",
        "      all_objects_evaluation_data = np.concatenate((all_objects_evaluation_data, evaluation_object_data), axis = 0)\n",
        "\n",
        "    all_objects_training_labels = all_objects_training_labels + number_of_training_examples*[object_index]\n",
        "    all_objects_evaluation_labels = all_objects_evaluation_labels + (NUMBER_OF_EXAMPLES_FOR_EACH_CLASS-number_of_training_examples)*[object_index]\n",
        "\n",
        "  return all_objects_training_data, np.array(all_objects_training_labels), all_objects_evaluation_data, np.array(all_objects_evaluation_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMnRE9_AkAkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(training_data, training_labels):\n",
        "  seq = Sequential()\n",
        "  # # # # #\n",
        "  seq.add(LSTM(1000, input_shape=(4,41), return_sequences=True, activation = \"tanh\"))\n",
        "  seq.add(LSTM(100, return_sequences=False, activation = \"tanh\"))\n",
        "  # # # # #\n",
        "  \n",
        "  seq.add(Dense(36, activation = \"softmax\"))\n",
        "  print(seq.summary())\n",
        "\n",
        "  seq.compile(optimizer=keras.optimizers.Adam(lr=0.00001),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=['accuracy'])\n",
        "  history = seq.fit(training_data, training_labels, batch_size = 16, epochs=700, validation_split = 0.2, shuffle = True)\n",
        "  return seq, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmXln57aSHX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Loading data.\")\n",
        "\n",
        "all_objects_training_data, all_objects_training_labels, all_objects_evaluation_data, all_objects_evaluation_labels = read_training_and_evaluation_objects_data(os.path.join(FUSION2020_FOLDER_PATH, \"Kinesthetic-Data\"), NUMBER_OF_EXAMPLES_FOR_TRAINING_AND_VALIDATION)\n",
        "all_objects_training_labels = keras.utils.to_categorical(all_objects_training_labels)\n",
        "all_objects_evaluation_labels = keras.utils.to_categorical(all_objects_evaluation_labels)\n",
        "print(all_objects_training_data.shape)\n",
        "print(all_objects_training_labels.shape)\n",
        "print(all_objects_evaluation_data.shape)\n",
        "print(all_objects_evaluation_labels.shape)\n",
        "reshaped_all_objects_training_data = all_objects_training_data\n",
        "reshaped_all_objects_training_data = list(reshaped_all_objects_training_data)\n",
        "all_objects_training_labels = list(all_objects_training_labels)\n",
        "zip_list = list(zip(reshaped_all_objects_training_data, all_objects_training_labels))\n",
        "random.shuffle(zip_list)\n",
        "reshaped_all_objects_training_data, all_objects_training_labels = zip(*zip_list)\n",
        "reshaped_all_objects_training_data = np.array(reshaped_all_objects_training_data)\n",
        "all_objects_training_labels = np.array(all_objects_training_labels)\n",
        "print(reshaped_all_objects_training_data.shape)\n",
        "\n",
        "print(np.min(reshaped_all_objects_training_data))\n",
        "print(np.max(reshaped_all_objects_training_data))\n",
        "model, history = train_model(reshaped_all_objects_training_data, all_objects_training_labels)\n",
        "print(all_objects_training_labels[9])\n",
        "reshaped_all_objects_evaluation_data = all_objects_evaluation_data\n",
        "\n",
        "score = model.evaluate(reshaped_all_objects_evaluation_data, all_objects_evaluation_labels)\n",
        "print('Test loss: {} / Test accuracy: {}'.format(score[0], score[1]))\n",
        " \n",
        "\n",
        "evaluation_predictions = model.predict(reshaped_all_objects_evaluation_data)\n",
        "print(evaluation_predictions.shape)\n",
        "\n",
        "output_matrix = -1 * np.ones((evaluation_predictions.shape[1],evaluation_predictions.shape[0]))\n",
        "\n",
        "for i in range(reshaped_all_objects_evaluation_data.shape[0]):\n",
        "  output_matrix[:,i] = evaluation_predictions[i]\n",
        "\n",
        "scipy.io.savemat(os.path.join(FUSION2020_FOLDER_PATH,'LSTMKinesthetic.mat'), {'output':output_matrix})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vfhSIQeHAkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_to_print = 10\n",
        "print(all_objects_training_data)\n",
        "print(np.max(all_objects_training_data))\n",
        "print(np.min(all_objects_training_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9pnb5APsrHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}