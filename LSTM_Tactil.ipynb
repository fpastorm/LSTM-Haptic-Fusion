{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTM-Tactil.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NeWVBhf1VxlH",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HKXgE6TyNCWx",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import scipy.io\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, Flatten, Dense, MaxPooling2D\n",
        "from keras.models import Sequential, load_model\n",
        "\n",
        "drive.mount('/content/gdrive')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bAHUc7Xk-I2y",
        "colab": {}
      },
      "source": [
        "#Add your own path\n",
        "FUSION2020_FOLDER_PATH = \"/content/gdrive/My Drive/FUSION2020\"\n",
        "NUMBER_OF_EXAMPLES_FOR_EACH_CLASS = 60\n",
        "NUMBER_OF_EXAMPLES_FOR_TRAINING_AND_VALIDATION = 15\n",
        "NUMBER_OF_SAMPLES_TO_IGNORE = 0\n",
        "RANDOM_TRAINING_AND_VALIDATION_EXAMPLES = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EPIYoswKSDmh",
        "colab": {}
      },
      "source": [
        "\n",
        "# Function to get the list of training examples paths\n",
        "# inputs:\n",
        "#   path:str -> Path to folder with .mat files.\n",
        "#   number_of_examples:int -> Number of examples to load for each class. Will be loaded examples from 1 to number_of_examples+1\n",
        "#   random_examples -> Do we select random examples?\n",
        "# outputs:\n",
        "#    If random_examples is false, it returns the first number_of_examples examples from each class. Else, number_of_examples random examples.\n",
        "\n",
        "def get_training_and_validation_example_list(path, number_of_examples, random_examples):\n",
        "  if random_examples:\n",
        "    all_examples_paths = glob(os.path.join(path, \"*.mat\"))\n",
        "    np.random.shuffle(all_examples_paths)\n",
        "    training_matrix_paths = all_examples_paths[:number_of_examples]\n",
        "  else:\n",
        "    training_matrix_paths = []\n",
        "    for i in range(1, number_of_examples+1):\n",
        "      training_matrix_paths = training_matrix_paths + glob(os.path.join(path, \"*_{}.mat\".format(i)))\n",
        "  return training_matrix_paths\n",
        "\n",
        "# Function to get the list of examples paths to ignore.\n",
        "# inputs:\n",
        "#   path:str -> Path to folder with .mat files.\n",
        "#   number_of_examples_to_ignore:int -> Number of examples to get.\n",
        "#   number_of_examples_to_use_for_training_and_validation:int -> Number of example to ignore before get number_of_examples_to_ignore\n",
        "# outputs:\n",
        "#   Unosrted list of examples with index from number_of_examples_to_use_for_training_and_validation+1 to number_of_examples_to_use_for_training_and_validation+number_of_examples_to_ignore\n",
        "\n",
        "def get_ignore_example_lists(path, number_of_examples_to_ignore, number_of_examples_to_use_for_training_and_validation):\n",
        "  ignore_example_list = []\n",
        "  for i in range(number_of_examples_to_use_for_training_and_validation+1, number_of_examples_to_use_for_training_and_validation + number_of_examples_to_ignore+1):\n",
        "    ignore_example_list = ignore_example_list + glob(os.path.join(path, \"*_{}.mat\".format(i)))\n",
        "  return ignore_example_list\n",
        "\n",
        "# Function to get all examples matrix paths.\n",
        "# inputs:\n",
        "#   path:str -> Path to folder with .mat files.\n",
        "# outputs:\n",
        "#   Unsorted list of all .mat in path.\n",
        "\n",
        "def get_all_matrix_paths(path):\n",
        "  number_of_matrix_paths = len(glob(os.path.join(path, \"*.mat\")))\n",
        "  all_matrix_paths = []\n",
        "  for i in range(1, number_of_matrix_paths+1):\n",
        "    all_matrix_paths = all_matrix_paths + glob(os.path.join(path, \"*_{}.mat\".format(i)))\n",
        "  return all_matrix_paths\n",
        "\n",
        "# Function to change a matrix index\n",
        "# inputs:\n",
        "#   matrix:nparray -> The matrix to change index.\n",
        "# outputs:\n",
        "#   matrix with index changed.\n",
        "\n",
        "def change_matrix_index(matrix):\n",
        "  print(\"Matrix to change input shape:\")\n",
        "  print(matrix.shape)\n",
        "  new_matrix = np.zeros([21,50,28])\n",
        "  for i in range(matrix.shape[2]):\n",
        "    new_matrix[i,:,:] = matrix[:,:,i]\n",
        "  return new_matrix\n",
        "\n",
        "# Function to read all .mat files and return training and evaluation sets.\n",
        "# inputs:\n",
        "#   path:str -> Path to folder with .mat files.\n",
        "#   number_of_training_examples:int -> Number of examples to use for training.\n",
        "#   number_of_examples_to_ignore:int -> Number of examples to ignore.\n",
        "# outputs:\n",
        "#   training data and evaluation data.\n",
        "\n",
        "def read_all_matrix_from_object_folder_obtaining_training_and_evaluation(path, number_of_training_examples, number_of_examples_to_ignore):\n",
        "  all_matrix_paths = get_all_matrix_paths(path)                                 # We get all .mat paths.\n",
        "  training_matrix_paths = get_training_and_validation_example_list(\n",
        "            path,number_of_training_examples, \n",
        "            RANDOM_TRAINING_AND_VALIDATION_EXAMPLES)                            # We get the list of .mat paths we will use to train the network.\n",
        "  ignore_example_list = get_ignore_example_lists(path, \n",
        "            number_of_examples_to_ignore, \n",
        "            number_of_training_examples)                                        # We get the list of examples to ignore.\n",
        "  print(training_matrix_paths)\n",
        "  training_object_data = None                                                   # We initilize the training data matrix as None.\n",
        "  evaluation_object_data = None                                                 # We initilize the evaluation data matrix as None.\n",
        "  training_matrix_index = 0                                                     # We initialize the training matrix index as 0. This index will be used to insert training data into training_object_data.\n",
        "  evaluation_matrix_index = 0                                                   # We initialize the evaluation matrix index as 0. This index will be used to insert training data into evaluation_object_data.\n",
        "\n",
        "  for matrix_path in all_matrix_paths:                                          # For each .mat path...\n",
        "    if not matrix_path in ignore_example_list:                                    # If we mustn't ignore it...\n",
        "      matrix = scipy.io.loadmat(matrix_path)                                        # We load the .mat as a matrix (numpy array).\n",
        "      matrix = change_matrix_index(matrix[\"frames2\"])                               # We change it index to fit in our desired data structure.\n",
        "      print(\"Matrix {} shape\".format(matrix_path))                              \n",
        "      print(matrix.shape)\n",
        "      if matrix_path in training_matrix_paths:                                      # If the matrix must be used as training data...\n",
        "        print(\"Training data\")\n",
        "        if training_object_data is None:                                              # If training_object_data has not been initialized as a matrix...\n",
        "          training_object_data = -1 * np.ones((len(training_matrix_paths), \n",
        "                                               matrix.shape[0], \n",
        "                                               matrix.shape[1], \n",
        "                                               matrix.shape[2]))                        # We initialize training_object_data as a matrix with -1 values as undefined.\n",
        "        training_object_data[training_matrix_index] = matrix                          # We insert the matrix into the first undefined training_object_data space defined by training_matrix_index.\n",
        "        training_matrix_index += 1                                                    # We increase training_matrix_index.\n",
        "\n",
        "      else:                                                                         # If the matrix mustn't be used as training data, it must be used as evaluation data...\n",
        "        print(\"Evaluation data\")\n",
        "        if evaluation_object_data is None:                                            # If evaluation_object_data has not been initialized as a matrix...\n",
        "          evaluation_object_data = -1 * np.ones((\n",
        "                                    (NUMBER_OF_EXAMPLES_FOR_EACH_CLASS\n",
        "                                      - len(training_matrix_paths) \n",
        "                                      - number_of_examples_to_ignore), \n",
        "                                    matrix.shape[0], \n",
        "                                    matrix.shape[1], \n",
        "                                    matrix.shape[2]))                                   # We initialize evaluation_object_data as a matrix with -1 values as undefined.\n",
        "        evaluation_object_data[evaluation_matrix_index] = matrix                      # We insert the matrix into the first undefined evaluation_object_data space defined by evaluation_matrix_index.\n",
        "        evaluation_matrix_index += 1                                                  # We increase evaluation_matrix_index.\n",
        "\n",
        "  print(\"Training object data shape:\")\n",
        "  print(training_object_data.shape)\n",
        "  print(\"Evaluation object data shape:\")\n",
        "  print(evaluation_object_data.shape)\n",
        "  return training_object_data, evaluation_object_data                           # We return training and evaluation data.\n",
        "\n",
        "\n",
        "# Function to get ordered training and evaluation objects.\n",
        "# inputs:\n",
        "#   path:str -> Folder with folders that contains .mats\n",
        "#   number_of_training_examples:int -> Number of examples used as training and evaluation\n",
        "#   number_of_examples_to_ignore:int -> Number of examples to don't read.\n",
        "# outputs:\n",
        "#   training data, training labels, evaluation data and evaluation labels.\n",
        "\n",
        "def read_training_and_evaluation_objects_data(path,number_of_training_examples, number_of_examples_to_ignore):\n",
        "  nom_labels = [\"antiseptic_bottle_\", \"ball_l_\",\"beard_shampoo_\", \"body_gel_\", \"basket_ball_\",\n",
        "                \"coke_bottle_\",\"constructable_green_brick_\", \"constructable_mixed_brick_\",\n",
        "                \"constructable_red_brick_\", \"constructable_yellow_brick_\", \"energy_drink_can_\", \n",
        "                 \"flux_bottle_\", \"gears_box_\", \"gorillas_ball_\", \"grey_mouse_\", \"mixed_nut_\", \n",
        "                \"mixed_washer_\", \"mouse_\", \"nestea_bottle_\",\"nut_m6_\", \"nut_m8_\", \"nut_m10_\",\n",
        "                \"rivets_box_\", \"roll_wheel_\", \"rubber_pipe_\", \"soda_can_\", \n",
        "                \"sponge_rough_\", \"sponge_rough_inclusions_\", \"sponge_scrunchy_\",\n",
        "                \"sponge_smooth_\", \"sponge_smooth_inclusions_\", \"sponge_tube_\", \n",
        "                \"sunscreen_lotion_\", \"tennis_ball_\", \"water_bottle_\",\"world_ball_\"]                                                # We define all labels (classes) names that match with subfolders names.\n",
        "  all_objects_folders_path = []                                                 # We initialize the list with folders paths.\n",
        "  print(path)\n",
        "  for nom_label in nom_labels:                                                  # For each label name...\n",
        "    all_objects_folders_path = all_objects_folders_path + glob(\n",
        "                                                  os.path.join(path,nom_label))   # We concatenate the subfolder path with that label to the all_objects_folders_path list.\n",
        "\n",
        "  all_objects_training_data = None                                              # We initialize the variable to contain training data (all_objects_training_data) as None.\n",
        "  all_objects_evaluation_data = None                                            # We initialize the variable to contain evaluation data (all_objects_evaluation_data) as None.\n",
        "  all_objects_training_labels = []                                              # We initialize the training data labels list (all_objects_training_labels) as None.\n",
        "  all_objects_evaluation_labels = []                                            # We initialize the evaluation data labels list (all_objects_evaluation_labels) as None.\n",
        "\n",
        "  for object_index, object_folder_path in enumerate(all_objects_folders_path):  # For each object class subfolder path and its index...\n",
        "    #print(object_folder_path)\n",
        "    training_object_data, evaluation_object_data = \\\n",
        "      read_all_matrix_from_object_folder_obtaining_training_and_evaluation(\n",
        "                                          object_folder_path,\n",
        "                                          number_of_training_examples, \n",
        "                                          number_of_examples_to_ignore)           # We get the training and evaluation objects data for that class.\n",
        "\n",
        "    if all_objects_training_data is None:                                         # If all_objects_training_data has not been initialized as a list...\n",
        "      all_objects_training_data = training_object_data                              # We initialize all_objects_training_data as the current training_object_data as initial list.\n",
        "    else:                                                                         # else...\n",
        "      all_objects_training_data = np.concatenate((all_objects_training_data, \n",
        "                                                  training_object_data), \n",
        "                                                axis = 0)                           # We concatenate current training_object_data list to all_objects_training_data.\n",
        "\n",
        "    if all_objects_evaluation_data is None:                                       # If all_objects_evaluation_data has not been initialized as a list...\n",
        "      all_objects_evaluation_data = evaluation_object_data                          # We initialize all_objects_evaluation_data as the current evaluation_object_data as initial list.\n",
        "    else:                                                                         # else...\n",
        "      all_objects_evaluation_data = np.concatenate((all_objects_evaluation_data,\n",
        "                                                    evaluation_object_data), \n",
        "                                                  axis = 0)                         # We concatenate current evaluation_object_data list to all_objects_evaluation_data.\n",
        "\n",
        "    all_objects_training_labels = all_objects_training_labels + \\\n",
        "                              number_of_training_examples*[object_index]          # We concatenate number_of_training_examples index values to all_objects_training_labels in order to have objects labels.\n",
        "    \n",
        "    number_of_evaluation_examples = (NUMBER_OF_EXAMPLES_FOR_EACH_CLASS\n",
        "                                      -number_of_training_examples\n",
        "                                      -number_of_examples_to_ignore)              # We get the number of evaluation examples.\n",
        "    \n",
        "    all_objects_evaluation_labels = all_objects_evaluation_labels + \\\n",
        "                              number_of_evaluation_examples*[object_index]        # We concatenate number of evaluation examples index values to all_objects_training_labels in order to have objects labels.\n",
        "\n",
        "  return (all_objects_training_data, np.array(all_objects_training_labels), \n",
        "          all_objects_evaluation_data, np.array(all_objects_evaluation_labels)) # We return training data, training labels, evaluation data and evaluation labels.\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMnRE9_AkAkI",
        "colab": {}
      },
      "source": [
        "# Function to define and train the classification network model.\n",
        "\n",
        "def train_model(training_data, training_labels):\n",
        "  seq = Sequential()\n",
        "  # # # # #\n",
        "  seq.add(ConvLSTM2D(8, (5, 5), input_shape=(21, 50, 28, 1), padding = \"same\", activation = \"tanh\"))\n",
        "  # # # # #\n",
        "  seq.add(Flatten())\n",
        "  seq.add(Dense(36, activation = \"softmax\"))\n",
        "  print(seq.summary())\n",
        "\n",
        "  seq.compile(optimizer=keras.optimizers.Adam(lr=0.0001),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=['accuracy'])\n",
        "  history = seq.fit(training_data, training_labels, batch_size = 16, epochs=30, validation_split = 0.2, shuffle = True)\n",
        "  return seq, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rmXln57aSHX8",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "print(\"Loading data.\")\n",
        "\n",
        "all_objects_training_data, all_objects_training_labels, all_objects_evaluation_data, all_objects_evaluation_labels = read_training_and_evaluation_objects_data(os.path.join(FUSION2020_FOLDER_PATH, \"Tactile-Data\"), NUMBER_OF_EXAMPLES_FOR_TRAINING_AND_VALIDATION, NUMBER_OF_SAMPLES_TO_IGNORE)\n",
        "all_objects_training_labels = keras.utils.to_categorical(all_objects_training_labels)\n",
        "all_objects_evaluation_labels = keras.utils.to_categorical(all_objects_evaluation_labels)\n",
        "print(\"Training data:\")\n",
        "print(all_objects_training_data.shape)\n",
        "print(\"Training labels:\")\n",
        "print(all_objects_training_labels.shape)\n",
        "print(\"Evaluation data:\")\n",
        "print(all_objects_evaluation_data.shape)\n",
        "print(\"Evaluation labels:\")\n",
        "print(all_objects_evaluation_labels.shape)\n",
        "\n",
        "reshaped_all_objects_training_data = np.expand_dims(all_objects_training_data, axis=-1) / 255.\n",
        "reshaped_all_objects_training_data = list(reshaped_all_objects_training_data)\n",
        "all_objects_training_labels = list(all_objects_training_labels)\n",
        "zip_list = list(zip(reshaped_all_objects_training_data, all_objects_training_labels))\n",
        "random.shuffle(zip_list)\n",
        "reshaped_all_objects_training_data, all_objects_training_labels = zip(*zip_list)\n",
        "reshaped_all_objects_training_data = np.array(reshaped_all_objects_training_data)\n",
        "all_objects_training_labels = np.array(all_objects_training_labels)\n",
        "print(reshaped_all_objects_training_data.shape)\n",
        "reshaped_all_objects_evaluation_data = np.expand_dims(all_objects_evaluation_data, axis=-1) / 255.\n",
        "\n",
        "print(np.min(reshaped_all_objects_training_data))\n",
        "print(np.max(reshaped_all_objects_training_data))\n",
        "model, history = train_model(reshaped_all_objects_training_data, all_objects_training_labels)\n",
        "print(all_objects_training_labels[9])\n",
        "\n",
        "score = model.evaluate(reshaped_all_objects_evaluation_data, all_objects_evaluation_labels)\n",
        "print('Test loss: {} / Test accuracy: {}'.format(score[0], score[1]))\n",
        "\n",
        "\n",
        "output_file = os.path.join(FUSION2020_FOLDER_PATH,'Tac_evaluation.txt')\n",
        "\n",
        "with open(output_file, 'w') as f:\n",
        "  print('Test loss: {} / Test accuracy: {}'.format(score[0], score[1]), file=f)  \n",
        "\n",
        "evaluation_predictions = model.predict(reshaped_all_objects_evaluation_data)\n",
        "print(evaluation_predictions.shape)\n",
        "\n",
        "output_matrix = -1 * np.ones((evaluation_predictions.shape[1],evaluation_predictions.shape[0]))\n",
        "\n",
        "for i in range(reshaped_all_objects_evaluation_data.shape[0]):\n",
        "  output_matrix[:,i] = evaluation_predictions[i]\n",
        "\n",
        "scipy.io.savemat(os.path.join(FUSION2020_FOLDER_PATH,'LSTMtactil.mat'), {'output':output_matrix})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2vfhSIQeHAkb",
        "colab": {}
      },
      "source": [
        "\n",
        "example_to_print = 10\n",
        "print(all_objects_training_data[example_to_print,1])\n",
        "print(np.max(all_objects_training_data[example_to_print,1]))\n",
        "print(np.min(all_objects_training_data[example_to_print,1]))\n",
        "print(np.sum(all_objects_training_data[example_to_print,1]==0))\n",
        "cv2_imshow(all_objects_training_data[example_to_print,1])\n",
        "for i in range(all_objects_training_data.shape[1]):\n",
        "  cv2_imshow(all_objects_training_data[example_to_print,i])\n",
        "\"\"\"\n",
        "plt.figure(figsize=(51,10))\n",
        "for i in range(51):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(all_objects_training_data[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l9pnb5APsrHd",
        "colab": {}
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}